{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deep_fib.sci_net import SCIBlockCfg, SCINet\n",
    "from deep_fib.data import DeepFIBDataset, get_masks\n",
    "from deep_fib.core import DeepFIBEngine\n",
    "\n",
    "from utils.data import Marconi100Dataset, get_train_test_split\n",
    "from utils.training import training_loop\n",
    "from utils.summary import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_train_test_split(0.5, 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[:len(train)//30]\n",
    "# test = test[:len(test)//10]\n",
    "# len(train), len(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 124/124 [00:37<00:00,  3.34it/s]\n",
      "Loading: 100%|██████████| 125/125 [00:43<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "m_data_train = Marconi100Dataset(train, normalize=True)\n",
    "m_data_test = Marconi100Dataset(test, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "horizon = 1024\n",
    "stride = 1000\n",
    "n_masks = 20\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "num_encoder_levels = 2\n",
    "\n",
    "log_dir = \"./trash\"\n",
    "lr = 1e-3\n",
    "num_epochs = 3\n",
    "step_size = 2\n",
    "\n",
    "hidden = None\n",
    "block_cfg = SCIBlockCfg(input_dim=460, hidden_size=4, kernel_size=3, dropout=0.5,)\n",
    "\n",
    "anomaly_threshold = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62080, 3187)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = DeepFIBDataset(\n",
    "    m_data_train, horizon=horizon, stride=stride\n",
    ")\n",
    "dataset_test = DeepFIBDataset(m_data_test, horizon=horizon, stride=stride)\n",
    "\n",
    "masks = get_masks(horizon, n_masks).float()\n",
    "\n",
    "len(dataset_train), len(dataset_test), masks.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1940, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=(num_workers != 0),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=(num_workers != 0),\n",
    ")\n",
    "len(train_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\deep_FIB.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=11'>12</a>\u001b[0m lr_sched \u001b[39m=\u001b[39m StepLR(optim, step_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m SummaryWriter(log_dir) \u001b[39mas\u001b[39;00m writer:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=14'>15</a>\u001b[0m     training_loop(\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=15'>16</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=16'>17</a>\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=17'>18</a>\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=18'>19</a>\u001b[0m         train_dataloader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=19'>20</a>\u001b[0m         test_dataloader\u001b[39m=\u001b[39;49mtest_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=20'>21</a>\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=21'>22</a>\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptim,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=22'>23</a>\u001b[0m         lr_scheduler\u001b[39m=\u001b[39;49mlr_sched,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=23'>24</a>\u001b[0m         writer\u001b[39m=\u001b[39;49mwriter,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=24'>25</a>\u001b[0m         save_path\u001b[39m=\u001b[39;49mlog_dir \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/models\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/deep_FIB.ipynb#ch0000007?line=25'>26</a>\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\utils\\training.py:58\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, engine, num_epochs, train_dataloader, test_dataloader, optimizer, device, lr_scheduler, writer, save_path)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=55'>56</a>\u001b[0m train_scalars \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n\u001b[0;32m     <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=56'>57</a>\u001b[0m test_scalars \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n\u001b[1;32m---> <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=57'>58</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_dataloader, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=58'>59</a>\u001b[0m     batch \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=59'>60</a>\u001b[0m         k: d\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, d \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=60'>61</a>\u001b[0m     }  \u001b[39m# type: Dict[str, Tensor]\u001b[39;00m\n\u001b[0;32m     <a href='file:///f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/utils/training.py?line=62'>63</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=365'>366</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=366'>367</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=367'>368</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=311'>312</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=312'>313</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=313'>314</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=919'>920</a>\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=920'>921</a>\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=921'>922</a>\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=922'>923</a>\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=923'>924</a>\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=924'>925</a>\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=925'>926</a>\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=926'>927</a>\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=927'>928</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=928'>929</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=117'>118</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=118'>119</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=119'>120</a>\u001b[0m _cleanup()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=122'>123</a>\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/process.py?line=123'>124</a>\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=221'>222</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=223'>224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=323'>324</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=325'>326</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/context.py?line=326'>327</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/popen_spawn_win32.py?line=90'>91</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/popen_spawn_win32.py?line=91'>92</a>\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/popen_spawn_win32.py?line=92'>93</a>\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/popen_spawn_win32.py?line=93'>94</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/popen_spawn_win32.py?line=94'>95</a>\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Zumo\\anaconda3\\envs\\torch-gpu\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/reduction.py?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/reduction.py?line=58'>59</a>\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Zumo/anaconda3/envs/torch-gpu/lib/multiprocessing/reduction.py?line=59'>60</a>\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SCINet(\n",
    "    output_len=horizon,\n",
    "    input_len=horizon,\n",
    "    num_encoder_levels=num_encoder_levels,\n",
    "    hidden_decoder_sizes=hidden,\n",
    "    block_config=block_cfg,\n",
    ").float()\n",
    "\n",
    "engine = DeepFIBEngine(anomaly_threshold, masks)\n",
    "\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "lr_sched = StepLR(optim, step_size)\n",
    "\n",
    "with SummaryWriter(log_dir) as writer:\n",
    "    training_loop(\n",
    "        model=model,\n",
    "        engine=engine,\n",
    "        num_epochs=num_epochs,\n",
    "        train_dataloader=train_loader,\n",
    "        test_dataloader=test_loader,\n",
    "        device=device,\n",
    "        optimizer=optim,\n",
    "        lr_scheduler=lr_sched,\n",
    "        writer=writer,\n",
    "        save_path=log_dir + \"/models\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=$log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c004a322e9c82f28ba2e77aacdbb1b6ccb0b2b4ae6a31db23bc8a8c53511ac4a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
