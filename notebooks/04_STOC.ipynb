{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def split_dataset(x: int, k: int):\n",
    "    end = False\n",
    "    step = 0\n",
    "    start = random.randint(0, x - 1)\n",
    "    subsets = []\n",
    "    l = list(range(x))\n",
    "    l_bool = [False for elem in l]\n",
    "\n",
    "    while not end:\n",
    "        # if there are enough indexes to make up another subset, make it\n",
    "        if l_bool.count(False) >= int(len(l) / k):\n",
    "            l_sub = []\n",
    "            while len(l_sub) < int(len(l) / k):\n",
    "                idx = (start + step) % len(l)\n",
    "                l_sub.append(l[idx])\n",
    "                l_bool[idx] = True\n",
    "                step += 1\n",
    "            subsets.append(l_sub)\n",
    "        else:\n",
    "            # if there are still indexes that haven't been assigned\n",
    "            l_sub_last = []\n",
    "            while l_bool.count(False) > 0:\n",
    "                idx = (start + step) % len(l)\n",
    "                l_sub_last.append(l[idx])\n",
    "                l_bool[idx] = True\n",
    "                step += 1\n",
    "            subsets.append(l_sub_last)\n",
    "            if len(l_sub_last) < 100:\n",
    "                # if the last sublist is too short merge it with the last one\n",
    "                merged_sub = subsets[-2] + subsets[-1]\n",
    "                subsets.pop(-1)\n",
    "                subsets.pop(-2)\n",
    "                subsets.append(merged_sub)\n",
    "            end = True\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 13, 14, 15, 16, 17],\n",
       " [18, 19, 20, 21, 22, 23],\n",
       " [24, 25, 26, 27, 28, 29],\n",
       " [3, 4, 5, 6, 7, 8],\n",
       " [3, 4, 5, 6, 7, 8, 9, 10, 11]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset(33, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "def split_dataset_indices(n_data: int, k: int) -> List[List[int]]:\n",
    "    # randomly roll indices\n",
    "    start = np.random.randint(0, n_data - 1)\n",
    "    idxs = list(np.roll(list(range(n_data)), start))\n",
    "\n",
    "    # get the len of each subset\n",
    "    sub_len, extras = divmod(n_data, k)\n",
    "    subsets_lens = [sub_len + 1 if i < extras else sub_len for i in range(k)]\n",
    "\n",
    "    # get start and end indices of each \"subset of indices\"\n",
    "    cum_lens = np.cumsum([0] + subsets_lens)\n",
    "    return [idxs[s:e] for s, e in zip(cum_lens[:-1], cum_lens[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7, 8, 9, 10, 11, 12],\n",
       " [13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24, 25, 26],\n",
       " [27, 28, 29, 30, 31, 32],\n",
       " [0, 1, 2, 3, 4, 5]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset_indices(33, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c004a322e9c82f28ba2e77aacdbb1b6ccb0b2b4ae6a31db23bc8a8c53511ac4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
