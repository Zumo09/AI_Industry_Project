{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from common import data\n",
    "from common.training import training_loop, get_predictions\n",
    "\n",
    "from algos import stoc2 as stoc\n",
    "from algos import cbl\n",
    "\n",
    "from common.models import simple_conv\n",
    "from common import metrics\n",
    "from common.models.modutils import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"./outs/stoc_2\"\n",
    "\n",
    "horizon = 1024\n",
    "stride = 512 + 128\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = list(range(1, 5))\n",
    "out_feats = 64\n",
    "k = 5\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "weight_decay = 1e-1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 2/2 [00:05<00:00,  2.84s/it]\n",
      "Loading: 100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "../data/r216n09.gzip - 16388 timesteps - 3.76% anomalies - len seq anomal 4.9\n",
    "../data/r229n10.gzip - 13239 timesteps - 4.21% anomalies - len seq anomal 4.6\n",
    "../data/r233n14.gzip - 15384 timesteps - 3.66% anomalies - len seq anomal 4.8\n",
    "\"\"\"\n",
    "train = [\"../data/r216n09.gzip\", \"../data/r229n10.gzip\"]\n",
    "test = [\"../data/r233n14.gzip\"]\n",
    "m_data_train = data.Marconi100Dataset(train, scaling=data.Scaling.STANDARD)\n",
    "m_data_test = data.Marconi100Dataset(test, scaling=data.Scaling.STANDARD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 24\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data.UnfoldedDataset(m_data_train, horizon=horizon, stride=stride)\n",
    "test_dataset = data.UnfoldedDataset(m_data_test, horizon=horizon, stride=stride)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_width = 128\n",
    "down_layers = 2\n",
    "dilations = [False, True]\n",
    "\n",
    "backbone = simple_conv.Encoder(data.NUM_FEATURES, down_layers, base_width, dilations)\n",
    "model = simple_conv.SimpleConv(backbone, out_feats, horizon)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "lr_sched = CosineAnnealingLR(optim, sum(num_epochs))\n",
    "\n",
    "aug = cbl.pipeline(\n",
    "    cbl.random_apply(cbl.left_to_right_flipping(1), 0.5),\n",
    "    cbl.random_apply(cbl.crop_and_resize(1.5, 3), 0.8),\n",
    ")\n",
    "\n",
    "engine = cbl.CBLEngine(\n",
    "    model=model,\n",
    "    optimizer=optim,\n",
    "    temperature=0.5,\n",
    "    aug_1=aug,\n",
    "    aug_2=aug,\n",
    "    lr_scheduler=lr_sched,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "stoc_engine = stoc.STOC(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:72: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  score_distr = np.array(\n",
      "f:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:72: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  score_distr = np.array(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\04_STOC.ipynb Cella 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m SummaryWriter(log_dir \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/logs\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m writer:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     stoc_engine\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         test_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         batch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         k,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         num_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         writer\u001b[39m=\u001b[39;49mwriter,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         save_path\u001b[39m=\u001b[39;49mlog_dir \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/models\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Users/Zumo/Documents/Github/AI_Industry_Project/notebooks/04_STOC.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:159\u001b[0m, in \u001b[0;36mSTOC.fit\u001b[1;34m(self, train_dataset, val_dataset, batch_size, k, epochs, writer, save_path)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    150\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    151\u001b[0m     train_dataset: UnfoldedDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     save_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_backbone(\n\u001b[0;32m    160\u001b[0m         train_dataset, val_dataset, batch_size, k, epochs, writer, save_path\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_kde(train_dataset, k)\n",
      "File \u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:188\u001b[0m, in \u001b[0;36mSTOC.fit_backbone\u001b[1;34m(self, train_dataset, val_dataset, batch_size, k, epochs, writer, save_path)\u001b[0m\n\u001b[0;32m    185\u001b[0m _log_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    187\u001b[0m \u001b[39mfor\u001b[39;00m i, num_epochs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epochs):\n\u001b[1;32m--> 188\u001b[0m     refined_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_refine_data(train_dataset, k)\n\u001b[0;32m    189\u001b[0m     data_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m    190\u001b[0m         refined_data,\n\u001b[0;32m    191\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m    192\u001b[0m         shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n",
      "File \u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:48\u001b[0m, in \u001b[0;36mSTOC._refine_data\u001b[1;34m(self, dataset, k)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_refine_data\u001b[39m(\u001b[39mself\u001b[39m, dataset: UnfoldedDataset, k: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Subset:\n\u001b[0;32m     47\u001b[0m     kdes, features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_subsets(dataset, k)\n\u001b[1;32m---> 48\u001b[0m     detections \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_detections(kde, features) \u001b[39mfor\u001b[39;00m kde \u001b[39min\u001b[39;00m kdes])\n\u001b[0;32m     50\u001b[0m     \u001b[39m# voting\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ensemble_output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_or\u001b[39m.\u001b[39mreduce(detections)\n",
      "File \u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_refine_data\u001b[39m(\u001b[39mself\u001b[39m, dataset: UnfoldedDataset, k: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Subset:\n\u001b[0;32m     47\u001b[0m     kdes, features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_subsets(dataset, k)\n\u001b[1;32m---> 48\u001b[0m     detections \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_detections(kde, features) \u001b[39mfor\u001b[39;00m kde \u001b[39min\u001b[39;00m kdes])\n\u001b[0;32m     50\u001b[0m     \u001b[39m# voting\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ensemble_output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_or\u001b[39m.\u001b[39mreduce(detections)\n",
      "File \u001b[1;32mf:\\Users\\Zumo\\Documents\\Github\\AI_Industry_Project\\notebooks\\algos\\stoc2.py:78\u001b[0m, in \u001b[0;36mSTOC._find_detections\u001b[1;34m(self, kde, features)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_find_detections\u001b[39m(\n\u001b[0;32m     65\u001b[0m     \u001b[39mself\u001b[39m, kde: KernelDensity, features: List[torch\u001b[39m.\u001b[39mTensor]\n\u001b[0;32m     66\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m     \u001b[39m# FEATURES : (N, T, F)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     score_distr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m     73\u001b[0m         [\n\u001b[0;32m     74\u001b[0m             kde\u001b[39m.\u001b[39mscore_samples(f)\n\u001b[0;32m     75\u001b[0m             \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m tqdm(features, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscore samples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m         ]\n\u001b[0;32m     77\u001b[0m     )  \u001b[39m# (N, T)\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     thr_range \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39mmin\u001b[39;49m(score_distr), \u001b[39mmax\u001b[39m(score_distr), \u001b[39m100\u001b[39m)\n\u001b[0;32m     80\u001b[0m     detections_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(features))])\n\u001b[0;32m     81\u001b[0m     \u001b[39mfor\u001b[39;00m thr \u001b[39min\u001b[39;00m thr_range:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "with SummaryWriter(log_dir + \"/logs\") as writer:\n",
    "    stoc_engine.fit(\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        batch_size,\n",
    "        k,\n",
    "        num_epochs,\n",
    "        writer=writer,\n",
    "        save_path=log_dir + \"/models\",\n",
    "    )\n",
    "\n",
    "\n",
    "# stoc_engine.fit(train_dataset, test_dataset, batch_size, k, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmodel = metrics.default_cmodel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "scores, labels = get_predictions(stoc_engine.predict, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmodel.fit(scores, labels).optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_cost(cmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_errors_curve(\n",
    "    cmodel.false_positives, cmodel.false_negatives, cmodel.thresholds, figsize=(15, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr, rec, f1 = metrics.precision_recall_f1(\n",
    "    cmodel.false_positives, cmodel.false_negatives\n",
    ")\n",
    "metrics.plot_precision_recall_f1_curve(pr, rec, f1, cmodel.thresholds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c004a322e9c82f28ba2e77aacdbb1b6ccb0b2b4ae6a31db23bc8a8c53511ac4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
